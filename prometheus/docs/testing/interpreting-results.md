# Interpreting Test Results

This guide explains how to read and analyze test reports generated by the Prometheus Testing Framework.

## Report Formats

The framework generates reports in multiple formats:

| Format | File | Best For |
|--------|------|----------|
| JSON | `test_report.json` | Programmatic analysis, CI/CD |
| Markdown | `test_report.md` | Documentation, Git commits |
| HTML | `test_report.html` | Human review, sharing |
| CSV | `test_report.csv` | Spreadsheet analysis |

## Report Structure

### Summary Section

Every report starts with a summary:

```
Test Results Summary
┌──────────────┬────────┐
│ Metric       │ Value  │
├──────────────┼────────┤
│ Status       │ PASSED │
│ Total Tests  │ 15     │
│ Passed       │ 14     │
│ Failed       │ 1      │
│ Skipped      │ 0      │
│ Success Rate │ 93.3%  │
│ Duration     │ 45.23s │
└──────────────┴────────┘
```

| Metric | Description |
|--------|-------------|
| Status | Overall result: PASSED or FAILED |
| Total Tests | Number of tests executed |
| Passed | Tests that met all criteria |
| Failed | Tests that failed criteria or errored |
| Skipped | Tests not executed (disabled or skipped) |
| Success Rate | Percentage of passed tests |
| Duration | Total execution time |

### Metadata Section

Contains test execution context:

```json
{
  "metadata": {
    "test_id": "550e8400-e29b-41d4-a716-446655440000",
    "timestamp": "2026-01-12T10:30:00Z",
    "platform": "minikube",
    "deployment_mode": "distributed",
    "prometheus_version": "v3.5.0",
    "duration_seconds": 45.23,
    "test_runner_host": {
      "os": "macOS",
      "python_version": "3.10.12",
      "k6_version": "0.47.0"
    }
  }
}
```


---

## Understanding Test Results

### Test Status Values

| Status | Meaning | Action Required |
|--------|---------|-----------------|
| `passed` | Test met all criteria | None |
| `failed` | Test did not meet criteria | Review failure details |
| `error` | Test encountered an error | Check error logs |
| `timeout` | Test exceeded time limit | Increase timeout or investigate |
| `skipped` | Test was not executed | Check if intentional |

### Individual Test Results

Each test includes detailed results:

```json
{
  "test_name": "api_accessible",
  "test_type": "sanity",
  "status": "passed",
  "duration_seconds": 2.15,
  "start_time": "2026-01-12T10:30:00Z",
  "end_time": "2026-01-12T10:30:02Z",
  "message": "API accessible at http://localhost:9090",
  "errors": [],
  "metrics": {},
  "metadata": {
    "endpoint": "/api/v1/status/config",
    "response_time_ms": 45
  }
}
```

---

## Analyzing Sanity Test Results

### Successful Sanity Test

```
Sanity Tests: PASSED (5/5)
├── api_accessible: PASSED (45ms)
├── healthcheck_healthy: PASSED (12ms)
├── healthcheck_ready: PASSED (15ms)
├── self_monitoring: PASSED (120ms)
└── basic_query: PASSED (85ms)
```

All endpoints are accessible and responding within thresholds.

### Failed Sanity Test

```
Sanity Tests: FAILED (3/5)
├── api_accessible: PASSED (45ms)
├── healthcheck_healthy: PASSED (12ms)
├── healthcheck_ready: FAILED
│   └── Error: HTTP 503 - Prometheus not ready
├── self_monitoring: PASSED (120ms)
└── basic_query: FAILED
    └── Error: Query timeout after 1000ms
```

**Troubleshooting:**
- `healthcheck_ready` failed: Prometheus may still be starting up or has issues
- `basic_query` failed: Query engine may be overloaded or misconfigured

---

## Analyzing Load Test Results

### k6 Metrics

Load tests using k6 report detailed metrics:

```json
{
  "k6_results": {
    "vus": 100,
    "iterations": 50000,
    "http_req_duration": {
      "avg": 25.5,
      "min": 5.2,
      "max": 450.3,
      "p50": 18.0,
      "p90": 45.0,
      "p95": 78.0,
      "p99": 120.0
    },
    "http_req_failed": 0.1,
    "http_reqs": 50000,
    "data_received": "125 MB",
    "data_sent": "15 MB"
  }
}
```

### Key Metrics to Watch

| Metric | Good | Warning | Critical |
|--------|------|---------|----------|
| p99 Latency | < 200ms | 200-500ms | > 500ms |
| p95 Latency | < 100ms | 100-300ms | > 300ms |
| Error Rate | < 0.1% | 0.1-1% | > 1% |
| Throughput | Stable | Declining | Dropping |

### Interpreting Latency Percentiles

```
Latency Distribution:
p50:  18ms  ████████████████████
p90:  45ms  ████████████████████████████████████████████
p95:  78ms  ██████████████████████████████████████████████████████████████████████████
p99: 120ms  ████████████████████████████████████████████████████████████████████████████████████████████████████████████████████
```

- **p50 (median)**: Half of requests complete faster than this
- **p90**: 90% of requests complete faster than this
- **p95**: 95% of requests complete faster than this
- **p99**: 99% of requests complete faster than this (tail latency)

**High p99 with low p50** indicates occasional slow requests (investigate outliers).
**High p50** indicates overall performance issues.

---

## Analyzing Stress Test Results

### Breaking Point Report

```json
{
  "stress_results": {
    "breaking_point": {
      "max_series": 5000000,
      "max_ingestion_rate": 500000,
      "max_concurrent_queries": 850,
      "failure_mode": "OOM",
      "failure_vus": 850
    },
    "k6_results": {
      "max_vus_reached": 800,
      "stages_completed": 2,
      "failure_point_vus": 850
    }
  }
}
```

### Understanding Breaking Points

| Metric | Description | Typical Values |
|--------|-------------|----------------|
| max_series | Maximum active series before failure | 1M - 10M |
| max_ingestion_rate | Maximum samples/second | 100K - 1M |
| max_concurrent_queries | Concurrent queries before degradation | 50 - 500 |
| failure_mode | How the system failed | OOM, Timeout, Error |


---

## Analyzing Performance Test Results

### Benchmark Results

```json
{
  "performance_results": {
    "simple_query_latency_ms": 35,
    "complex_query_latency_ms": 280,
    "range_query_1h_latency_ms": 150,
    "range_query_24h_latency_ms": 850,
    "api_endpoints": {
      "/api/v1/query": {"avg_ms": 35, "p99_ms": 85},
      "/api/v1/query_range": {"avg_ms": 150, "p99_ms": 450},
      "/api/v1/labels": {"avg_ms": 25, "p99_ms": 60},
      "/api/v1/series": {"avg_ms": 120, "p99_ms": 350}
    }
  }
}
```

### Comparing Against Thresholds

| Metric | Result | Threshold | Status |
|--------|--------|-----------|--------|
| Simple Query | 35ms | < 50ms | ✅ PASS |
| Complex Query | 280ms | < 500ms | ✅ PASS |
| Range Query (1h) | 150ms | < 200ms | ✅ PASS |
| Range Query (24h) | 850ms | < 1000ms | ✅ PASS |

---

## Analyzing Reliability Test Results

### Recovery Test Results

```json
{
  "reliability_results": {
    "recovery_tests": {
      "pod_restart": {
        "status": "passed",
        "recovery_time_seconds": 45,
        "data_loss_percent": 0
      },
      "wal_replay": {
        "status": "passed",
        "replay_time_seconds": 12,
        "samples_recovered": 1500000
      },
      "network_partition": {
        "status": "passed",
        "partition_duration_seconds": 30,
        "recovery_time_seconds": 5
      }
    }
  }
}
```

### Key Reliability Metrics

| Metric | Good | Acceptable | Poor |
|--------|------|------------|------|
| Recovery Time | < 30s | 30-60s | > 60s |
| Data Loss | 0% | < 0.1% | > 0.1% |
| WAL Replay | < 30s | 30-120s | > 120s |

---

## Error Analysis

### Error Format

```json
{
  "errors": [
    {
      "error_code": "PROM_UNREACHABLE",
      "message": "Cannot connect to Prometheus at http://localhost:9090",
      "category": "network",
      "severity": "critical",
      "context": {
        "url": "http://localhost:9090",
        "timeout_ms": 5000
      },
      "remediation": "Verify Prometheus is running and accessible",
      "timestamp": "2026-01-12T10:30:15Z"
    }
  ]
}
```

### Common Error Codes

| Error Code | Category | Description | Remediation |
|------------|----------|-------------|-------------|
| `PROM_UNREACHABLE` | network | Cannot connect to Prometheus | Check URL and network |
| `QUERY_TIMEOUT` | execution | Query exceeded timeout | Increase timeout or optimize query |
| `AUTH_FAILED` | validation | Authentication failed | Check credentials |
| `THRESHOLD_EXCEEDED` | validation | Metric exceeded threshold | Investigate performance |
| `OOM_DETECTED` | execution | Out of memory | Increase resources |
| `CONFIG_INVALID` | configuration | Invalid configuration | Check config file |

---

## Generating Reports

### Convert JSON to Other Formats

```bash
# Generate HTML report
python3 -m tests.cli report --input results/test_report.json --format html

# Generate multiple formats
python3 -m tests.cli report --input results/test_report.json -f html -f markdown -f csv

# Custom output directory
python3 -m tests.cli report --input results/test_report.json --output ./reports
```

### Report Files

After running tests, find reports in the output directory:

```
results/
├── test_report.json      # Full JSON report
├── test_report.md        # Markdown summary
├── test_report.html      # HTML report with charts
└── test_report.csv       # CSV for spreadsheet analysis
```

---

## Comparing Results

### Version Comparison

Compare results between Prometheus versions:

```bash
# Run tests on v3.4.0
python3 -m tests.cli run --type performance --output results/v3.4.0

# Run tests on v3.5.0
python3 -m tests.cli run --type performance --output results/v3.5.0

# Compare manually or use diff tools
diff results/v3.4.0/test_report.json results/v3.5.0/test_report.json
```

### Trend Analysis

Track metrics over time by archiving reports:

```bash
# Archive with timestamp
cp results/test_report.json "archive/$(date +%Y%m%d_%H%M%S)_report.json"
```

---

## Troubleshooting Failed Tests

### Step 1: Check Summary

Look at the overall status and identify which tests failed.

### Step 2: Review Error Details

Find the specific error messages and codes.

### Step 3: Check Context

Review the test metadata and context for clues.

### Step 4: Verify Environment

Ensure Prometheus is running and accessible:

```bash
python3 -m tests.cli status --platform docker
```

### Step 5: Check Logs

Review Prometheus logs for errors:

```bash
# Docker
docker logs prometheus

# Kubernetes
kubectl logs -n monitoring prometheus-0
```

### Step 6: Re-run with Verbose Output

```bash
python3 -m tests.cli run --type sanity --verbose
```

---

## Best Practices

1. **Archive Reports**: Keep historical reports for trend analysis
2. **Set Baselines**: Establish performance baselines for comparison
3. **Monitor Trends**: Watch for gradual degradation over time
4. **Investigate Outliers**: High p99 with low p50 indicates intermittent issues
5. **Correlate with Changes**: Link test results to configuration or version changes
6. **Automate Analysis**: Use JSON reports for automated threshold checking in CI/CD
